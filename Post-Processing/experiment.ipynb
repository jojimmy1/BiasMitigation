{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/li3975/cs587\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "# import calib_eq_odds as eq\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "sys.path.append(cwd + \"/Post-Processing\")\n",
    "from calib_eq_odds import Model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "fn_rate = 1\n",
    "fp_rate = 0\n",
    "\n",
    "kiva_label = \"dataAug/kiva_label.csv\"\n",
    "student_label = \"dataAug/studentperf_label.csv\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(kiva_label)\n",
    "data['repayment_interval'] = data['repayment_interval'].replace(2, 1)\n",
    "train_data = data [0:20000]\n",
    "target = train_data['repayment_interval']\n",
    "target = torch.tensor(target.values).float()\n",
    "X = train_data.drop(['repayment_interval'], axis=1)\n",
    "X = torch.tensor(X.values).float()\n",
    "gender_index = data.columns.get_loc('borrower_genders')\n",
    "val_data = data[20000: 40000]\n",
    "val_target = val_data['repayment_interval']\n",
    "val_target = torch.tensor(val_target.values).float()\n",
    "val_X = val_data.drop(['repayment_interval'], axis=1)\n",
    "val_X = torch.tensor(val_X.values).float()\n",
    "test_data = data[40000:]\n",
    "test_target = test_data['repayment_interval']\n",
    "test_target = torch.tensor(test_target.values).float()\n",
    "test_X = test_data.drop(['repayment_interval'], axis=1)\n",
    "test_X = torch.tensor(test_X.values).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, num_columns):\n",
    "        # Call the parent constructor to initialize the nn.Module\n",
    "        super(LogisticRegression, self).__init__()\n",
    "\n",
    "        # Define a linear transformation layer (weights and bias) for the model.\n",
    "        # `x_female.shape[1]` specifies the number of input features, and `out_features=1` indicates a single output for binary classification.\n",
    "        # The bias term is included by setting bias=True, allowing the model to learn an intercept.\n",
    "        self.w = nn.Linear(num_columns, out_features=1, bias=True)\n",
    "\n",
    "        # Initialize a sigmoid activation function, which will be used to convert logits to probabilities.\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Define the forward pass for the model.\n",
    "        # Apply the linear transformation to the input `x`.\n",
    "        w = self.w(x)\n",
    "\n",
    "        # Apply the sigmoid function to the output of the linear layer.\n",
    "        # This converts the logits (raw output of the linear layer) to probabilities in the range (0, 1).\n",
    "        output = self.sigmoid(w)\n",
    "\n",
    "        # Return the output probabilities.\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model):\n",
    "    \n",
    "    ceriation = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    model.train()\n",
    "    for epoch in range(100):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X)\n",
    "        loss = ceriation(output.squeeze(1), target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print('epoch [{}/{}], loss:{:.4f}'.format(epoch + 1, 100, loss.item()))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/100], loss:5.3077\n",
      "epoch [2/100], loss:5.0745\n",
      "epoch [3/100], loss:4.1778\n",
      "epoch [4/100], loss:4.0531\n",
      "epoch [5/100], loss:3.9799\n",
      "epoch [6/100], loss:3.8328\n",
      "epoch [7/100], loss:3.8292\n",
      "epoch [8/100], loss:3.8237\n",
      "epoch [9/100], loss:3.8070\n",
      "epoch [10/100], loss:3.9329\n",
      "epoch [11/100], loss:3.9672\n",
      "epoch [12/100], loss:3.9887\n",
      "epoch [13/100], loss:4.0008\n",
      "epoch [14/100], loss:4.0167\n",
      "epoch [15/100], loss:4.0085\n",
      "epoch [16/100], loss:3.9889\n",
      "epoch [17/100], loss:3.9778\n",
      "epoch [18/100], loss:3.9682\n",
      "epoch [19/100], loss:3.9309\n",
      "epoch [20/100], loss:3.8091\n",
      "epoch [21/100], loss:3.7956\n",
      "epoch [22/100], loss:3.7953\n",
      "epoch [23/100], loss:3.7780\n",
      "epoch [24/100], loss:3.7806\n",
      "epoch [25/100], loss:3.7904\n",
      "epoch [26/100], loss:3.7872\n",
      "epoch [27/100], loss:3.7848\n",
      "epoch [28/100], loss:3.7876\n",
      "epoch [29/100], loss:3.7953\n",
      "epoch [30/100], loss:3.7947\n",
      "epoch [31/100], loss:3.7939\n",
      "epoch [32/100], loss:3.7928\n",
      "epoch [33/100], loss:3.7915\n",
      "epoch [34/100], loss:3.7902\n",
      "epoch [35/100], loss:3.7851\n",
      "epoch [36/100], loss:3.7680\n",
      "epoch [37/100], loss:3.7553\n",
      "epoch [38/100], loss:3.7427\n",
      "epoch [39/100], loss:3.7506\n",
      "epoch [40/100], loss:3.7498\n",
      "epoch [41/100], loss:3.7574\n",
      "epoch [42/100], loss:3.7612\n",
      "epoch [43/100], loss:3.7734\n",
      "epoch [44/100], loss:3.7772\n",
      "epoch [45/100], loss:3.7726\n",
      "epoch [46/100], loss:3.7636\n",
      "epoch [47/100], loss:3.7546\n",
      "epoch [48/100], loss:3.7456\n",
      "epoch [49/100], loss:3.7452\n",
      "epoch [50/100], loss:3.7405\n",
      "epoch [51/100], loss:3.7399\n",
      "epoch [52/100], loss:3.7434\n",
      "epoch [53/100], loss:3.7427\n",
      "epoch [54/100], loss:3.7422\n",
      "epoch [55/100], loss:3.7417\n",
      "epoch [56/100], loss:3.7410\n",
      "epoch [57/100], loss:3.7402\n",
      "epoch [58/100], loss:3.7186\n",
      "epoch [59/100], loss:3.7181\n",
      "epoch [60/100], loss:3.7133\n",
      "epoch [61/100], loss:3.6916\n",
      "epoch [62/100], loss:3.6530\n",
      "epoch [63/100], loss:3.6522\n",
      "epoch [64/100], loss:3.6513\n",
      "epoch [65/100], loss:3.6501\n",
      "epoch [66/100], loss:3.6490\n",
      "epoch [67/100], loss:3.6437\n",
      "epoch [68/100], loss:3.6427\n",
      "epoch [69/100], loss:3.6206\n",
      "epoch [70/100], loss:3.6069\n",
      "epoch [71/100], loss:3.5931\n",
      "epoch [72/100], loss:3.5878\n",
      "epoch [73/100], loss:3.5740\n",
      "epoch [74/100], loss:3.5476\n",
      "epoch [75/100], loss:3.5045\n",
      "epoch [76/100], loss:3.5028\n",
      "epoch [77/100], loss:3.4970\n",
      "epoch [78/100], loss:3.4870\n",
      "epoch [79/100], loss:3.4811\n",
      "epoch [80/100], loss:3.4753\n",
      "epoch [81/100], loss:3.4651\n",
      "epoch [82/100], loss:3.4508\n",
      "epoch [83/100], loss:3.4406\n",
      "epoch [84/100], loss:3.4345\n",
      "epoch [85/100], loss:3.4283\n",
      "epoch [86/100], loss:3.4180\n",
      "epoch [87/100], loss:3.3950\n",
      "epoch [88/100], loss:3.3636\n",
      "epoch [89/100], loss:3.3447\n",
      "epoch [90/100], loss:3.2666\n",
      "epoch [91/100], loss:3.1888\n",
      "epoch [92/100], loss:3.1356\n",
      "epoch [93/100], loss:3.0860\n",
      "epoch [94/100], loss:3.0404\n",
      "epoch [95/100], loss:2.8429\n",
      "epoch [96/100], loss:2.6193\n",
      "epoch [97/100], loss:2.1502\n",
      "epoch [98/100], loss:1.7268\n",
      "epoch [99/100], loss:0.6674\n",
      "epoch [100/100], loss:2.4265\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(9)\n",
    "model = train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with no grad\n",
    "group_0_val_pred = []\n",
    "group_1_val_pred = []\n",
    "group_0_val_gt= []\n",
    "group_1_val_gt = []\n",
    "\n",
    "group_0_test_pred = []\n",
    "group_1_test_pred = []\n",
    "group_0_test_gt= []\n",
    "group_1_test_gt = []\n",
    "\n",
    "def evaluated_nn(model, val_X, val_target, test_X, test_target):\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in zip(val_X, val_target):\n",
    "            y_pred = model(x)\n",
    "            if x[gender_index] == 0:\n",
    "                group_0_val_pred.append(y_pred.item())\n",
    "                group_0_val_gt.append(y.item())\n",
    "            else:\n",
    "                group_1_val_pred.append(y_pred.item())\n",
    "                group_1_val_gt.append(y.item())\n",
    "            # print(f'Prediction: {y_pred.item()}, True: {y.item()}')\n",
    "        \n",
    "        for x, y in zip(test_X, test_target):\n",
    "            y_pred = model(x)\n",
    "            if x[gender_index] == 0:\n",
    "                group_0_test_pred.append(y_pred.item())\n",
    "                group_0_test_gt.append(y.item())\n",
    "            else:\n",
    "                group_1_test_pred.append(y_pred.item())\n",
    "                group_1_test_gt.append(y.item())\n",
    "            # print(f'Prediction: {y_pred.item()}, True: {y.item()}')\n",
    "\n",
    "evaluated_nn(model, val_X, val_target, test_X, test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original group 0 model:\n",
      "Accuracy:\t0.949\n",
      "F.P. cost:\t0.981\n",
      "F.N. cost:\t0.001\n",
      "Base rate:\t0.949\n",
      "Avg. score:\t0.998\n",
      "\n",
      "Original group 1 model:\n",
      "Accuracy:\t0.782\n",
      "F.P. cost:\t0.981\n",
      "F.N. cost:\t0.002\n",
      "Base rate:\t0.780\n",
      "Avg. score:\t0.994\n",
      "\n",
      "Equalized odds group 0 model:\n",
      "Accuracy:\t0.949\n",
      "F.P. cost:\t0.980\n",
      "F.N. cost:\t0.002\n",
      "Base rate:\t0.949\n",
      "Avg. score:\t0.997\n",
      "\n",
      "Equalized odds group 1 model:\n",
      "Accuracy:\t0.782\n",
      "F.P. cost:\t0.981\n",
      "F.N. cost:\t0.002\n",
      "Base rate:\t0.780\n",
      "Avg. score:\t0.994\n",
      "\n"
     ]
    }
   ],
   "source": [
    "group_0_val_model = Model(np.array(group_0_val_pred), np.array(group_0_val_gt))\n",
    "group_1_val_model = Model(np.array(group_1_val_pred), np.array(group_1_val_gt))\n",
    "group_0_test_model = Model(np.array(group_0_test_pred), np.array(group_0_test_gt))\n",
    "group_1_test_model = Model(np.array(group_1_test_pred), np.array(group_1_test_gt))\n",
    "_, _, mix_rates = Model.calib_eq_odds(group_0_val_model, group_1_val_model, fp_rate, fn_rate)\n",
    "calib_eq_odds_group_0_test_model, calib_eq_odds_group_1_test_model = Model.calib_eq_odds(\n",
    "    group_0_test_model, group_1_test_model, fp_rate, fn_rate, mix_rates)\n",
    "print('Original group 0 model:\\n%s\\n' % repr(group_0_test_model))\n",
    "print('Original group 1 model:\\n%s\\n' % repr(group_1_test_model))\n",
    "print('Equalized odds group 0 model:\\n%s\\n' % repr(calib_eq_odds_group_0_test_model))\n",
    "print('Equalized odds group 1 model:\\n%s\\n' % repr(calib_eq_odds_group_1_test_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Hours_Studied', 'Attendance', 'Sleep_Hours',\n",
      "       'Previous_Scores', 'Motivation_Level', 'Tutoring_Sessions',\n",
      "       'Family_Income', 'Teacher_Quality', 'Physical_Activity',\n",
      "       'Learning_Disabilities', 'Parental_Education_Level',\n",
      "       'Distance_from_Home', 'Gender', 'Exam_Score'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(student_label)\n",
    "print(data.columns)\n",
    "average_score = data['Exam_Score'].mean()   \n",
    "data['Exam_Score'] = data['Exam_Score'].apply(lambda x: 1 if x > average_score else 0)\n",
    "train_data = data [0:2000]\n",
    "target = train_data['Exam_Score']\n",
    "target = torch.tensor(target.values).float()\n",
    "X = train_data.drop(['Exam_Score'], axis=1)\n",
    "X = torch.tensor(X.values).float()\n",
    "gender_index = data.columns.get_loc('Gender')\n",
    "val_data = data[2000: 4000]\n",
    "val_target = val_data['Exam_Score']\n",
    "val_target = torch.tensor(val_target.values).float()\n",
    "val_X = val_data.drop(['Exam_Score'], axis=1)\n",
    "val_X = torch.tensor(val_X.values).float()\n",
    "test_data = data[4000:]\n",
    "test_target = test_data['Exam_Score']\n",
    "test_target = torch.tensor(test_target.values).float()\n",
    "test_X = test_data.drop(['Exam_Score'], axis=1)\n",
    "test_X = torch.tensor(test_X.values).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (20000x9 and 14x1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m14\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m group_0_val_pred \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m group_1_val_pred \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[0;32mIn[16], line 8\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(num_columns)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m):\n\u001b[1;32m      7\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m----> 8\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     loss \u001b[38;5;241m=\u001b[39m ceriation(output\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m), target)\n\u001b[1;32m     10\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.conda/envs/cent7/2024.02-py311/work/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/cent7/2024.02-py311/work/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[22], line 17\u001b[0m, in \u001b[0;36mLogisticRegression.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# Define the forward pass for the model.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# Apply the linear transformation to the input `x`.\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m     w \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m# Apply the sigmoid function to the output of the linear layer.\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# This converts the logits (raw output of the linear layer) to probabilities in the range (0, 1).\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigmoid(w)\n",
      "File \u001b[0;32m~/.conda/envs/cent7/2024.02-py311/work/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/cent7/2024.02-py311/work/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/cent7/2024.02-py311/work/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (20000x9 and 14x1)"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(14)\n",
    "train(model)\n",
    "\n",
    "group_0_val_pred = []\n",
    "group_1_val_pred = []\n",
    "group_0_val_gt= []\n",
    "group_1_val_gt = []\n",
    "\n",
    "group_0_test_pred = []\n",
    "group_1_test_pred = []\n",
    "group_0_test_gt= []\n",
    "group_1_test_gt = []\n",
    "evaluated_nn(model, val_X, val_target, test_X, test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_0_val_model = Model(np.array(group_0_val_pred), np.array(group_0_val_gt))\n",
    "group_1_val_model = Model(np.array(group_1_val_pred), np.array(group_1_val_gt))\n",
    "group_0_test_model = Model(np.array(group_0_test_pred), np.array(group_0_test_gt))\n",
    "group_1_test_model = Model(np.array(group_1_test_pred), np.array(group_1_test_gt))\n",
    "_, _, mix_rates = Model.calib_eq_odds(group_0_val_model, group_1_val_model, fp_rate, fn_rate)\n",
    "calib_eq_odds_group_0_test_model, calib_eq_odds_group_1_test_model = Model.calib_eq_odds(\n",
    "    group_0_test_model, group_1_test_model, fp_rate, fn_rate, mix_rates)\n",
    "print('Original group 0 model:\\n%s\\n' % repr(group_0_test_model))\n",
    "print('Original group 1 model:\\n%s\\n' % repr(group_1_test_model))\n",
    "print('Equalized odds group 0 model:\\n%s\\n' % repr(calib_eq_odds_group_0_test_model))\n",
    "print('Equalized odds group 1 model:\\n%s\\n' % repr(calib_eq_odds_group_1_test_model))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
