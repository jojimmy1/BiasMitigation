{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/li3975/cs587\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "# import calib_eq_odds as eq\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "sys.path.append(cwd + \"/Post-Processing\")\n",
    "from calib_eq_odds import Model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "fn_rate = 1\n",
    "fp_rate = 0\n",
    "\n",
    "kiva_label = \"dataAug/kiva_label.csv\"\n",
    "student_label = \"dataAug/student_label.csv\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(kiva_label)\n",
    "data['repayment_interval'] = data['repayment_interval'].replace(2, 1)\n",
    "\n",
    "train_data = data [0:20000]\n",
    "target = train_data['repayment_interval']\n",
    "\n",
    "target = torch.tensor(target.values).float()\n",
    "X = train_data.drop(['repayment_interval'], axis=1)\n",
    "X = torch.tensor(X.values).float()\n",
    "gender_index = data.columns.get_loc('borrower_genders')\n",
    "\n",
    "# val_test_data = data[20000:]\n",
    "# val_testl_target = val_test_data['repayment_interval']\n",
    "# val_test_target = torch.tensor(val_test_data.values).float()\n",
    "# val_test_X = val_test_data.drop(['repayment_interval'], axis=1)\n",
    "# val_test_X = torch.tensor(val_test_X.values).float()\n",
    "val_data = data[20000: 40000]\n",
    "val_target = val_data['repayment_interval']\n",
    "val_target = torch.tensor(val_target.values).float()\n",
    "val_X = val_data.drop(['repayment_interval'], axis=1)\n",
    "val_X = torch.tensor(val_X.values).float()\n",
    "test_data = data[40000:]\n",
    "test_target = test_data['repayment_interval']\n",
    "test_target = torch.tensor(test_target.values).float()\n",
    "test_X = test_data.drop(['repayment_interval'], axis=1)\n",
    "test_X = torch.tensor(test_X.values).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        # Call the parent constructor to initialize the nn.Module\n",
    "        super(LogisticRegression, self).__init__()\n",
    "\n",
    "        # Define a linear transformation layer (weights and bias) for the model.\n",
    "        # `x_female.shape[1]` specifies the number of input features, and `out_features=1` indicates a single output for binary classification.\n",
    "        # The bias term is included by setting bias=True, allowing the model to learn an intercept.\n",
    "        self.w = nn.Linear(9, out_features=1, bias=True)\n",
    "\n",
    "        # Initialize a sigmoid activation function, which will be used to convert logits to probabilities.\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Define the forward pass for the model.\n",
    "        # Apply the linear transformation to the input `x`.\n",
    "        w = self.w(x)\n",
    "\n",
    "        # Apply the sigmoid function to the output of the linear layer.\n",
    "        # This converts the logits (raw output of the linear layer) to probabilities in the range (0, 1).\n",
    "        output = self.sigmoid(w)\n",
    "\n",
    "        # Return the output probabilities.\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train loss: 23.014047622680664\n",
      "Epoch 1: train loss: 16.86544418334961\n",
      "Epoch 2: train loss: 12.541253089904785\n",
      "Epoch 3: train loss: 9.297276496887207\n",
      "Epoch 4: train loss: 6.8834404945373535\n",
      "Epoch 5: train loss: 5.491730213165283\n",
      "Epoch 6: train loss: 4.827389717102051\n",
      "Epoch 7: train loss: 4.43923807144165\n",
      "Epoch 8: train loss: 4.270114421844482\n",
      "Epoch 9: train loss: 4.89850378036499\n",
      "Epoch 10: train loss: 5.0890069007873535\n",
      "Epoch 11: train loss: 5.279667854309082\n",
      "Epoch 12: train loss: 5.304134368896484\n",
      "Epoch 13: train loss: 5.352044105529785\n",
      "Epoch 14: train loss: 5.3869733810424805\n",
      "Epoch 15: train loss: 5.428093910217285\n",
      "Epoch 16: train loss: 5.425224781036377\n",
      "Epoch 17: train loss: 5.431719779968262\n",
      "Epoch 18: train loss: 5.4386372566223145\n",
      "Epoch 19: train loss: 5.437448501586914\n",
      "Epoch 20: train loss: 5.436474800109863\n",
      "Epoch 21: train loss: 5.448347091674805\n",
      "Epoch 22: train loss: 5.448090076446533\n",
      "Epoch 23: train loss: 5.448210716247559\n",
      "Epoch 24: train loss: 5.452722549438477\n",
      "Epoch 25: train loss: 5.465656757354736\n",
      "Epoch 26: train loss: 5.465969562530518\n",
      "Epoch 27: train loss: 5.470475196838379\n",
      "Epoch 28: train loss: 5.470758438110352\n",
      "Epoch 29: train loss: 5.471018314361572\n",
      "Epoch 30: train loss: 5.471258640289307\n",
      "Epoch 31: train loss: 5.471482276916504\n",
      "Epoch 32: train loss: 5.471683025360107\n",
      "Epoch 33: train loss: 5.47186279296875\n",
      "Epoch 34: train loss: 5.472033977508545\n",
      "Epoch 35: train loss: 5.472169399261475\n",
      "Epoch 36: train loss: 5.47231912612915\n",
      "Epoch 37: train loss: 5.472451686859131\n",
      "Epoch 38: train loss: 5.472579479217529\n",
      "Epoch 39: train loss: 5.47268009185791\n",
      "Epoch 40: train loss: 5.472756862640381\n",
      "Epoch 41: train loss: 5.472819805145264\n",
      "Epoch 42: train loss: 5.472959995269775\n",
      "Epoch 43: train loss: 5.473017692565918\n",
      "Epoch 44: train loss: 5.473052501678467\n",
      "Epoch 45: train loss: 5.473066329956055\n",
      "Epoch 46: train loss: 5.47307825088501\n",
      "Epoch 47: train loss: 5.47319221496582\n",
      "Epoch 48: train loss: 5.473305702209473\n",
      "Epoch 49: train loss: 5.47331428527832\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = LogisticRegression()\n",
    "ceriation = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "model.train()\n",
    "for epoch in range(50):\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model(X)\n",
    "    loss = ceriation(y_pred.squeeze(), target)\n",
    "    # print(f'Epoch {epoch}: y_pred: {y_pred.squeeze()}')\n",
    "    print(f'Epoch {epoch}: train loss: {loss.item()}')\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with no grad\n",
    "group_0_val_pred = []\n",
    "group_1_val_pred = []\n",
    "group_0_val_gt= []\n",
    "group_1_val_gt = []\n",
    "\n",
    "group_0_test_pred = []\n",
    "group_1_test_pred = []\n",
    "group_0_test_gt= []\n",
    "group_1_test_gt = []\n",
    "\n",
    "\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for x, y in zip(val_X, val_target):\n",
    "        y_pred = model(x)\n",
    "        if x[gender_index] == 0:\n",
    "            group_0_val_pred.append(y_pred.item())\n",
    "            group_0_val_gt.append(y.item())\n",
    "        else:\n",
    "            group_1_val_pred.append(y_pred.item())\n",
    "            group_1_val_gt.append(y.item())\n",
    "        # print(f'Prediction: {y_pred.item()}, True: {y.item()}')\n",
    "    \n",
    "    for x, y in zip(test_X, test_target):\n",
    "        y_pred = model(x)\n",
    "        if x[gender_index] == 0:\n",
    "            group_0_test_pred.append(y_pred.item())\n",
    "            group_0_test_gt.append(y.item())\n",
    "        else:\n",
    "            group_1_test_pred.append(y_pred.item())\n",
    "            group_1_test_gt.append(y.item())\n",
    "        # print(f'Prediction: {y_pred.item()}, True: {y.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_0_val_model = Model(np.array(group_0_val_pred), np.array(group_0_val_gt))\n",
    "group_1_val_model = Model(np.array(group_1_val_pred), np.array(group_1_val_gt))\n",
    "group_0_test_model = Model(np.array(group_0_test_pred), np.array(group_0_test_gt))\n",
    "group_1_test_model = Model(np.array(group_1_test_pred), np.array(group_1_test_gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original group 0 model:\n",
      "Accuracy:\t0.937\n",
      "F.P. cost:\tnan\n",
      "F.N. cost:\t0.050\n",
      "Base rate:\t0.999\n",
      "Avg. score:\t0.949\n",
      "\n",
      "Original group 1 model:\n",
      "Accuracy:\t0.773\n",
      "F.P. cost:\tnan\n",
      "F.N. cost:\t0.209\n",
      "Base rate:\t0.998\n",
      "Avg. score:\t0.780\n",
      "\n",
      "Equalized odds group 0 model:\n",
      "Accuracy:\t0.937\n",
      "F.P. cost:\tnan\n",
      "F.N. cost:\t0.050\n",
      "Base rate:\t0.999\n",
      "Avg. score:\t0.949\n",
      "\n",
      "Equalized odds group 1 model:\n",
      "Accuracy:\t0.773\n",
      "F.P. cost:\tnan\n",
      "F.N. cost:\t0.209\n",
      "Base rate:\t0.998\n",
      "Avg. score:\t0.780\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/li3975/cs587/Post-Processing/calib_eq_odds.py:82: RuntimeWarning: Mean of empty slice.\n",
      "  return self.pred[self.label == 0].mean()\n",
      "/home/li3975/.conda/envs/cent7/2024.02-py311/work/lib/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "_, _, mix_rates = Model.calib_eq_odds(group_0_val_model, group_1_val_model, fp_rate, fn_rate)\n",
    "calib_eq_odds_group_0_test_model, calib_eq_odds_group_1_test_model = Model.calib_eq_odds(\n",
    "    group_0_test_model, group_1_test_model, fp_rate, fn_rate, mix_rates)\n",
    "print('Original group 0 model:\\n%s\\n' % repr(group_0_test_model))\n",
    "print('Original group 1 model:\\n%s\\n' % repr(group_1_test_model))\n",
    "print('Equalized odds group 0 model:\\n%s\\n' % repr(calib_eq_odds_group_0_test_model))\n",
    "print('Equalized odds group 1 model:\\n%s\\n' % repr(calib_eq_odds_group_1_test_model))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
