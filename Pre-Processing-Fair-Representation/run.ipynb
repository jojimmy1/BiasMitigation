{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/li3975/cs587/Pre-Processing-Fair-Representation/model/utils/dataloader.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  target.replace(['High', 'Medium', 'Low'], [2, 1, 0], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>fit_called<<<<<<<<<<\n",
      "250 12501.637984834588\n",
      "500 12501.596016632542\n",
      "750 -13483.221421406715\n",
      "1000 -13483.223002110688\n",
      "1250 -108864.12006767662\n",
      "1500 -108864.07806226703\n",
      "1750 -108864.08069454822\n",
      "2000 -130909.75482814513\n",
      "2250 -130909.749419526\n",
      "2500 -139701.46001165887\n",
      "2750 -139701.43081849933\n",
      "3000 -139701.45437986162\n",
      "3250 -154805.15667087122\n",
      "3500 -154805.1517506894\n",
      "3750 -157141.01220768603\n",
      "4000 -157140.9972835059\n",
      "4250 -157141.0059213479\n",
      "4500 -158913.0147377762\n",
      "4750 -158912.98372212632\n",
      "5000 -160062.00011805614\n",
      "5250 -160061.99172011373\n",
      "5500 -160061.96836385503\n",
      "5750 -161345.66702805844\n",
      "6000 -161345.67232056145\n",
      "6250 -163247.90210560986\n",
      "6500 -163247.90557934612\n",
      "6750 -163247.90261661628\n",
      "7000 -166286.95386653516\n",
      "7250 -166286.9637732659\n",
      "7500 -172002.11146548772\n",
      "7750 -172002.10549788468\n",
      "8000 -172002.13443206358\n",
      "8250 -209700.40649713384\n",
      "8500 -209700.40647893574\n",
      "8750 -209701.15400391776\n",
      "9000 -209701.1540038659\n",
      "9250 -209701.15400380906\n",
      "9500 -209704.1368837469\n",
      "9750 -209704.1374679228\n",
      "10000 -209715.9766216356\n",
      "10250 -209715.9766070379\n",
      "10500 -209715.97660698424\n",
      "10750 -209762.26480047687\n",
      "11000 -209762.26487891158\n",
      "11250 -209930.4408099452\n",
      "11500 -209930.4406846669\n",
      "11750 -209930.44068486427\n",
      "12000 -210441.561545044\n",
      "12250 -210441.56154599998\n",
      "12500 -210444.12573537606\n",
      "12750 -210444.12573546244\n",
      "13000 -210444.1257352525\n",
      "13250 -210446.3084115027\n",
      "13500 -210446.3084195159\n",
      "13750 -210442.8738409999\n",
      "14000 -210442.8738394596\n",
      "14250 -210442.87383954192\n",
      "14500 -210447.903256679\n",
      "14750 -210447.90325675657\n",
      "15000 -210450.96133693564\n",
      "15250 -210450.96133683156\n",
      "15500 -210450.96133685263\n",
      "15750 -210452.4147740136\n",
      "16000 -210452.4147740181\n",
      "16250 -210452.4731603399\n",
      "16500 -210452.47315967953\n",
      "16750 -210452.47315926864\n",
      "17000 -210452.9003425077\n",
      "17250 -210452.900342387\n",
      "17500 -210452.9338784288\n",
      "17750 -210452.93387598355\n",
      "18000 -210452.9338774888\n",
      "18250 -210453.10792534146\n",
      "18500 -210453.1079254067\n",
      "18750 -210452.9543773069\n",
      "19000 -210452.95437416702\n",
      "19250 -210452.95437424842\n",
      "19500 -210453.2519676701\n",
      "19750 -210453.25196717327\n",
      "20000 -210453.4885338043\n",
      "20250 -210453.48853344074\n",
      "20500 -210453.48853349529\n",
      "20750 -210416.1329727939\n",
      "21000 -210416.13297145828\n",
      "21250 -210453.59441300255\n",
      "21500 -210453.5944124761\n",
      "21750 -210453.59441209387\n",
      "22000 -210453.69893521696\n",
      "22250 -210453.6989327847\n",
      "22500 -210452.70716279052\n",
      "22750 -210452.70716424368\n",
      "23000 -210452.70716338433\n",
      "23250 -210453.74430494427\n",
      "23500 -210453.74430278857\n",
      "23750 -210453.86682075405\n",
      "24000 -210453.8668205547\n",
      "24250 -210453.86682041042\n",
      "24500 -210454.10297517\n",
      "24750 -210454.10297594234\n",
      "25000 -210454.24032747958\n",
      "25250 -210454.2403266141\n",
      "25500 -210454.24032649238\n",
      "25750 -210454.44765253732\n",
      "26000 -210454.44765450654\n",
      "26250 -210454.7443797399\n",
      "26500 -210454.74438394763\n",
      "26750 -210454.74438291794\n",
      "27000 -210455.0197800341\n",
      "27250 -210455.01978068228\n",
      "27500 -210455.0347606374\n",
      "27750 -210455.03475774964\n",
      "28000 -210455.0347577008\n",
      "28250 -210455.23970602636\n",
      "28500 -210455.23970699657\n",
      "28750 -210454.14853776692\n",
      "29000 -210454.1485382742\n",
      "29250 -210454.14853837338\n",
      "29500 -210455.4979669412\n",
      "29750 -210455.49797148368\n",
      "30000 -210455.9640767268\n",
      "30250 -210455.96407718142\n",
      "30500 -210455.9640773137\n",
      "30750 -210450.66065313775\n",
      "31000 -210450.66065777832\n",
      "31250 -210456.67226281448\n",
      "31500 -210456.67226043725\n",
      "31750 -210456.67226056184\n",
      "32000 -210454.54627742438\n",
      "32250 -210454.54627888478\n",
      "32500 -210456.97446634268\n",
      "32750 -210456.97446575083\n",
      "33000 -210456.97446633832\n",
      "33250 -210457.40271303995\n",
      "33500 -210457.40271241663\n",
      "33750 -210457.57782098633\n",
      "34000 -210457.57782077536\n",
      "34250 -210457.577820983\n",
      "34500 -210457.831899594\n",
      "34750 -210457.831897291\n",
      "35000 -210457.43264476315\n",
      "35250 -210457.43264448093\n",
      "35500 -210457.43264478375\n",
      "35750 -210458.10162587697\n",
      "36000 -210458.1016258205\n",
      "36250 -210458.2592873727\n",
      "36500 -210458.25928676306\n",
      "36750 -210458.25928610525\n",
      "37000 -210458.42817946835\n",
      "37250 -210458.4281801611\n",
      "37500 -210458.7981679369\n",
      "37750 -210458.79816908634\n",
      "38000 -210458.79816738187\n",
      "38250 -210458.95471558344\n",
      "38500 -210458.95471536348\n",
      "38750 -210458.96558603708\n",
      "39000 -210458.96558533763\n",
      "39250 -210459.05487229233\n",
      "39500 -210459.05487547707\n",
      "39750 -210459.05487221663\n",
      "40000 -210457.89122671806\n",
      "40250 -210457.89122872436\n",
      "40500 -210459.02904437602\n",
      "40750 -210459.02908003877\n",
      "41000 -210459.02908007868\n",
      "41250 -210459.0519364254\n",
      "41500 -210459.0519353617\n",
      "41750 -210459.05554158663\n",
      "42000 -210459.0555389708\n",
      "42250 -210459.0555401427\n",
      "42500 -210459.09781805737\n",
      "42750 -210459.097817895\n",
      "43000 -210459.2160360208\n",
      "43250 -210459.2160359418\n",
      "43500 -210459.2160364989\n",
      "43750 -210459.66867703886\n",
      "44000 -210459.66867679023\n",
      "44250 -210459.39671828967\n",
      "44500 -210459.39671970243\n",
      "44750 -210459.3967197455\n",
      "45000 -210459.72501641355\n",
      "45250 -210459.7250177564\n",
      "45500 -210459.87162930434\n",
      "45750 -210459.871628884\n",
      "46000 -210459.87162910655\n",
      "46250 -210458.98875759062\n",
      "46500 -210458.98875933827\n",
      "46750 -210460.11243052676\n",
      "47000 -210460.11243096038\n",
      "47250 -210460.11243206073\n",
      "47500 -210460.2385751861\n",
      "47750 -210460.238577351\n",
      "48000 -210459.86133100963\n",
      "48250 -210459.86133264177\n",
      "48500 -210459.86133413273\n",
      "48750 -210460.45667481897\n",
      "49000 -210460.45667733796\n",
      "49250 -210460.64622781271\n",
      "49500 -210460.64622890373\n",
      "49750 -210460.64622747607\n",
      "50000 -210460.3712628947\n",
      "50250 -210460.37126328872\n",
      "50500 -210460.79668994647\n",
      "50750 -210460.79668679694\n",
      "51000 -210460.7966877826\n",
      "51250 -210460.96927378705\n",
      "51500 -210460.96927170892\n",
      "51750 -210460.91544369952\n",
      "52000 -210460.91544524767\n",
      "52250 -210460.91544425857\n",
      "52500 -210461.04685710036\n",
      "52750 -210461.04685814172\n",
      "53000 -210461.01532187584\n",
      "53250 -210461.01532269694\n",
      "53500 -210461.0153210969\n",
      "53750 -210461.07085157186\n",
      "54000 -210461.07085156723\n",
      "54250 -210461.08447148118\n",
      "54500 -210461.0844716901\n",
      "54750 -210461.0844716721\n",
      "55000 -210461.09012473418\n",
      "55250 -210461.090126018\n",
      "55500 -210460.8165339791\n",
      "55750 -210460.81653526946\n",
      "56000 -210460.81653475366\n",
      "56250 -210461.08710887696\n",
      "56500 -210461.08710919312\n",
      "56750 -210461.09917572062\n",
      "57000 -210461.0991747013\n",
      "57250 -210461.09917617135\n",
      "57500 -210461.10638721753\n",
      "57750 -210461.10639058397\n",
      "58000 -210461.11011828264\n",
      "58250 -210461.110117705\n",
      "58500 -210461.11011556088\n",
      "58750 -210461.10716650012\n",
      "59000 -210461.1071661686\n",
      "59250 -210461.11078207963\n",
      "59500 -210461.11077801528\n",
      "59750 -210461.11077951975\n",
      "60000 -210461.11054292918\n",
      "60250 -210461.1105404405\n",
      "60500 -210461.1108581762\n",
      "60750 -210461.11085658777\n",
      "61000 -210461.1108570278\n",
      "61250 -210461.09665778338\n",
      "61500 -210461.09665684265\n",
      "61750 -210461.11108454748\n",
      "62000 -210461.11108354773\n",
      "62250 -210461.11108389826\n",
      ">>>>>>>>>>Transform_called<<<<<<<<<<\n",
      ">>>>>>>>>>Transform_called<<<<<<<<<<\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "At least one label specified must be in y_true",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 119\u001b[0m\n\u001b[1;32m    117\u001b[0m Y_pred[classification] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(Y_pred[classification] \u001b[38;5;241m>\u001b[39m thresh)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64)  \u001b[38;5;66;03m# Apply threshold to predictions\u001b[39;00m\n\u001b[1;32m    118\u001b[0m ACC \u001b[38;5;241m=\u001b[39m accuracy_score(y_train[classification], Y_pred[classification])  \u001b[38;5;66;03m# Calculate accuracy\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m DEO \u001b[38;5;241m=\u001b[39m \u001b[43mDifferenceEqualOpportunity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY_pred\u001b[49m\u001b[43m[\u001b[49m\u001b[43mclassification\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msensitive_feature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassification\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Equal opportunity difference\u001b[39;00m\n\u001b[1;32m    120\u001b[0m DAO \u001b[38;5;241m=\u001b[39m DifferenceAverageOdds(Y_pred[classification], y_train, sensitive_feature, classification, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m])  \u001b[38;5;66;03m# Average odds difference\u001b[39;00m\n\u001b[1;32m    121\u001b[0m bal_acc_arr_transf\u001b[38;5;241m.\u001b[39mappend(ACC)\n",
      "File \u001b[0;32m~/cs587/Pre-Processing-Fair-Representation/model/utils/metrics.py:65\u001b[0m, in \u001b[0;36mDifferenceEqualOpportunity\u001b[0;34m(y_pred, y_real, SensitiveCat, outcome, privileged, unprivileged, labels)\u001b[0m\n\u001b[1;32m     62\u001b[0m y_real_unpriv \u001b[38;5;241m=\u001b[39m y_real[y_real[SensitiveCat] \u001b[38;5;241m==\u001b[39m unprivileged]\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Compute confusion matrix for the privileged group and extract TN, FP, FN, TP\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m TN_priv, FP_priv, FN_priv, TP_priv \u001b[38;5;241m=\u001b[39m \u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_real_priv\u001b[49m\u001b[43m[\u001b[49m\u001b[43moutcome\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_priv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mravel()\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Compute confusion matrix for the unprivileged group and extract TN, FP, FN, TP\u001b[39;00m\n\u001b[1;32m     68\u001b[0m TN_unpriv, FP_unpriv, FN_unpriv, TP_unpriv \u001b[38;5;241m=\u001b[39m confusion_matrix(y_real_unpriv[outcome], y_unpriv, labels\u001b[38;5;241m=\u001b[39mlabels)\u001b[38;5;241m.\u001b[39mravel()\n",
      "File \u001b[0;32m~/.conda/envs/cent7/2024.02-py311/lfr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:321\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mzeros((n_labels, n_labels), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39mintersect1d(y_true, labels)) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 321\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one label specified must be in y_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    324\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones(y_true\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint64)\n",
      "\u001b[0;31mValueError\u001b[0m: At least one label specified must be in y_true"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "import sys\n",
    "sys.path.append('/home/li3975/cs587/Pre-Processing-Fair-Representation/')\n",
    "\n",
    "from model.utils.metrics import *\n",
    "from model.utils.dataloader import dataloader\n",
    "from model.LFR import LFR\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "random.seed(42)  # Fixes the seed for Python's random module to ensure consistent results\n",
    "np.random.seed(42)  # Fixes the seed for NumPy's random module for consistency\n",
    "\n",
    "\n",
    "sensitive_features = {'credit': 'V5', \n",
    "                      'student':  'Family_Income',\n",
    "                      'kiva': 'Borrower_genders', \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "dataSet = \"student\"\n",
    "sensitive_feature = sensitive_features[dataSet]\n",
    "# Load and preprocess the dataset using a custom dataloader\n",
    "# Dataloader returns the dataset, target labels, numerical, and categorical features\n",
    "\n",
    "data = dataloader(dataSet, sensitive_feature) \n",
    "dataset, target, numvars, categorical = data  # Unpack the returned values\n",
    "\n",
    "# print(dataset)\n",
    "# print(target)\n",
    "\n",
    "\n",
    "# Split the dataset into training and testing sets with stratified sampling to maintain target distribution\n",
    "x_train, x_test, y_train, y_test = train_test_split(dataset,\n",
    "                                                    target,\n",
    "                                                    test_size=0.1,\n",
    "                                                    random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# Remove the sensitive feature ('gender') from the classification target\n",
    "classification = target.columns.to_list()  # Get a list of target columns\n",
    "classification.remove(sensitive_feature)  # Remove the sensitive feature\n",
    "classification = classification[0]  # Select the primary classification target feature\n",
    "\n",
    "# Create a pipeline to standardize numerical features\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[('scaler', StandardScaler())])  # Standardizes numerical data by removing the mean and scaling to unit variance\n",
    "\n",
    "# Create a pipeline to one-hot encode categorical features\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))])  # Transforms categorical variables into binary vectors\n",
    "\n",
    "# Combine numerical and categorical transformations\n",
    "transformations = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numvars),  # Apply numeric transformation to numeric columns\n",
    "        ('cat', categorical_transformer, categorical)])  # Apply categorical transformation to categorical columns\n",
    "\n",
    "# Build a pipeline that preprocesses both numerical and categorical data\n",
    "pipeline = Pipeline(steps=[('preprocessor', transformations)])  \n",
    "dict_all_result_in_grid = {}  # Initialize an empty dictionary to store grid search results\n",
    "\n",
    "# Apply the transformation pipeline to the training data\n",
    "x_train = pipeline.fit_transform(x_train)\n",
    "\n",
    "# Set parameters for the LFR fairness transformation model\n",
    "parameters = {'k': 10, 'Ax': 0.001, 'Ay': 0.1, 'Az': 10.0, 'max_iter': 150000, 'max_fun': 150000}\n",
    "\n",
    "# Instantiate the LFR (Learning Fair Representations) model\n",
    "lfr = LFR(sensitive_feature=sensitive_feature, privileged_class=1, unprivileged_class=0, seed=42,\n",
    "            output_feature=classification, parameter=parameters)\n",
    "\n",
    "# Train the LFR model on the transformed training data\n",
    "lfr.fit(X=x_train, y=y_train)\n",
    "\n",
    "# Transform the training data into fair representations using LFR\n",
    "Z_train, y_trainLFR = lfr.transform(X=x_train, y=y_train)\n",
    "\n",
    "# Initialize arrays to store results for accuracy and fairness metrics\n",
    "bal_acc_arr_transf = []\n",
    "deo_arr_transf = []\n",
    "dao_arr_transf = []\n",
    "FairDEO = []\n",
    "FairDAO = []\n",
    "\n",
    "# Define a range of thresholds to evaluate the trade-off between accuracy and fairness\n",
    "thresholds = np.linspace(0.01, 0.99, 100)\n",
    "\n",
    "# Initialize and train an SVM classifier with a linear kernel on the transformed training data\n",
    "svc = SVC(kernel='linear')\n",
    "svc.fit(Z_train, y_train[classification])\n",
    "\n",
    "# Apply the transformation pipeline to the test data\n",
    "x_test = pipeline.transform(x_test)\n",
    "\n",
    "# Transform the test data using the LFR model\n",
    "Z_test, y_testLFR = lfr.transform(X=x_test, y=y_test)\n",
    "\n",
    "# Predict the classification labels for the test set using the trained SVM\n",
    "y_pred = svc.predict(Z_test)\n",
    "\n",
    "# Calculate accuracy of the SVM predictions on the test set\n",
    "ACC = accuracy_score(y_pred, y_test[classification])\n",
    "\n",
    "# Loop through each threshold and evaluate the accuracy and fairness metrics\n",
    "for thresh in thresholds:\n",
    "    Y_pred = y_trainLFR.copy()  # Copy the training labels after LFR transformation\n",
    "    Y_pred[classification] = np.array(Y_pred[classification] > thresh).astype(np.float64)  # Apply threshold to predictions\n",
    "    ACC = accuracy_score(y_train[classification], Y_pred[classification])  # Calculate accuracy\n",
    "    DEO = DifferenceEqualOpportunity(Y_pred[classification], y_train, sensitive_feature, classification, 1, 0, [0, 1])  # Equal opportunity difference\n",
    "    DAO = DifferenceAverageOdds(Y_pred[classification], y_train, sensitive_feature, classification, 1, 0, [0, 1])  # Average odds difference\n",
    "    bal_acc_arr_transf.append(ACC)\n",
    "    deo_arr_transf.append(DEO)\n",
    "    dao_arr_transf.append(DAO)\n",
    "    FairDEO.append(ACC * (1 - DEO))  # Weighted fairness with DEO\n",
    "    FairDAO.append(ACC * (1 - DAO))  # Weighted fairness with DAO\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the trade-off between accuracy and fairness metrics for the training set\n",
    "plt.title(\"tradeOff Accuracy-Fairness for different thresholds (TRAIN)\")\n",
    "plt.plot(thresholds, bal_acc_arr_transf, marker='.')\n",
    "plt.plot(thresholds, deo_arr_transf, marker='.')\n",
    "plt.plot(thresholds, dao_arr_transf, marker='.')\n",
    "plt.plot(thresholds, FairDEO, marker='.')\n",
    "plt.plot(thresholds, FairDAO, marker='.')\n",
    "plt.ylim(0, 1)\n",
    "plt.legend([\"ACC\", \"DEO\", \"DAO\", \"F_DEO\", \"F_DAO\"])\n",
    "plt.xlabel(\"threshold\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear arrays to store test results\n",
    "bal_acc_arr_transf = []\n",
    "deo_arr_transf = []\n",
    "dao_arr_transf = []\n",
    "FairDEO = []\n",
    "FairDAO = []\n",
    "\n",
    "# Evaluate accuracy and fairness metrics on the test data\n",
    "for thresh in thresholds:\n",
    "    Y_pred = y_testLFR.copy()\n",
    "    Y_pred[classification] = np.array(Y_pred[classification] > thresh).astype(np.float64)\n",
    "    ACC = accuracy_score(y_test[classification], Y_pred[classification])\n",
    "    DEO = DifferenceEqualOpportunity(Y_pred[classification], y_test, sensitive_feature, classification, 1, 0, [0, 1])\n",
    "    DAO = DifferenceAverageOdds(Y_pred[classification], y_test, sensitive_feature, classification, 1, 0, [0, 1])\n",
    "    bal_acc_arr_transf.append(ACC)\n",
    "    deo_arr_transf.append(DEO)\n",
    "    dao_arr_transf.append(DAO)\n",
    "    FairDEO.append(ACC * (1 - DEO))\n",
    "    FairDAO.append(ACC * (1 - DAO))\n",
    "\n",
    "# Plot the trade-off between accuracy and fairness metrics for the test set\n",
    "plt.title(\"tradeOff Accuracy-Fairness for different thresholds (TEST)\")\n",
    "plt.plot(thresholds, bal_acc_arr_transf, marker='.')\n",
    "plt.plot(thresholds, deo_arr_transf, marker='.')\n",
    "plt.plot(thresholds, dao_arr_transf, marker='.')\n",
    "plt.plot(thresholds, FairDEO, marker='.')\n",
    "plt.plot(thresholds, FairDAO, marker='.')\n",
    "plt.ylim(0, 1)\n",
    "plt.legend([\"ACC\", \"DEO\", \"DAO\", \"F_DEO\", \"F_DAO\"])\n",
    "plt.xlabel(\"threshold\")\n",
    "plt.show()\n",
    "\n",
    "# Print accuracy and fairness metrics based on Zemel's method\n",
    "print(\"Next the metrics used by zemel, et al.\")\n",
    "print(\"Accuracy: {}\".format(accuracy(y_test[classification], y_testLFR[classification])))\n",
    "print(\"Discrimination: {}\".format(discrimination(\n",
    "    y_test, y_testLFR[classification], sensitive_feature, 1, 0)))\n",
    "print(\"Consistency: {}\".format(consistency(x_test, y_testLFR[classification], k=5)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
